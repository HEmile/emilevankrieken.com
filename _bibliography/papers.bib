@article{alivanistos2022prompting,
  title = {Prompting as Probing: {{Using}} Language Models for Knowledge Base Construction},
  author = {Alivanistos, D and Báez Santamarı́a, S and Cochez, M and Kalo, J-C and family=Krieken, given=E, prefix=van, useprefix=true and Thanapalasingam, T and others},
  date = {2022},
  publisher = {AachenCEUR-WS}
}

@article{danieleRefiningNeuralNetwork2023a,
  title = {Refining Neural Network Predictions Using Background Knowledge},
  author = {Daniele, Alessandro and family=Krieken, given=Emile, prefix=van, useprefix=true and Serafini, Luciano and family=Harmelen, given=Frank, prefix=van, useprefix=true},
  date = {2023-03-14},
  journaltitle = {Machine Learning},
  shortjournal = {Mach Learn},
  issn = {1573-0565},
  doi = {10.1007/s10994-023-06310-3},
  url = {https://doi.org/10.1007/s10994-023-06310-3},
  urldate = {2023-03-29},
  abstract = {Recent work has shown learning systems can use logical background knowledge to compensate for a lack of labeled training data. Many methods work by creating a loss function that encodes this knowledge. However, often the logic is discarded after training, even if it is still helpful at test time. Instead, we ensure neural network predictions satisfy the knowledge by refining the predictions with an extra computation step. We introduce differentiable refinement functions that find a corrected prediction close to the original prediction. We study how to effectively and efficiently compute these refinement functions. Using a new algorithm called iterative local refinement (ILR), we combine refinement functions to find refined predictions for logical formulas of any complexity. ILR finds refinements on complex SAT formulas in significantly fewer iterations and frequently finds solutions where gradient descent can not. Finally, ILR produces competitive results in the MNIST addition task.},
  langid = {english},
  keywords = {Fuzzy logic,Neurosymbolic AI,Optimization}
}

@inproceedings{heinerman2018benefits,
  title = {Benefits of Social Learning in Physical Robots},
  booktitle = {2018 {{IEEE}} Symposium Series on Computational Intelligence ({{SSCI}})},
  author = {Heinerman, Jacqueline and Bussmann, Bart and Groenendijk, Rick and Van Krieken, Emile and Slik, Jesper and Tezza, Alessandro and Haasdijk, Evert and family=Eiben, given=AE, given-i=AE},
  date = {2018},
  pages = {851--858},
  publisher = {IEEE}
}

@inproceedings{marconatoBEARSMakeNeuroSymbolic2024,
  title = {{{BEARS Make Neuro-Symbolic Models Aware}} of Their {{Reasoning Shortcuts}}},
  author = {Marconato, Emanuele and Bortolotti, Samuele and family=Krieken, given=Emile, prefix=van, useprefix=true and Vergari, Antonio and Passerini, Andrea and Teso, Stefano},
  date = {2024-02-19},
  abstract = {Neuro-Symbolic (NeSy) predictors that conform to symbolic knowledge - encoding, e.g., safety constraints - can be affected by Reasoning Shortcuts (RSs): They learn concepts consistent with the symbolic knowledge by exploiting unintended semantics. RSs compromise reliability and generalization and, as we show in this paper, they are linked to NeSy models being overconfident about the predicted concepts. Unfortunately, the only trustworthy mitigation strategy requires collecting costly dense supervision over the concepts. Rather than attempting to avoid RSs altogether, we propose to ensure NeSy models are aware of the semantic ambiguity of the concepts they learn, thus enabling their users to identify and distrust low-quality concepts. Starting from three simple desiderata, we derive bears (BE Aware of Reasoning Shortcuts), an ensembling technique that calibrates the model's concept-level confidence without compromising prediction accuracy, thus encouraging NeSy architectures to be uncertain about concepts affected by RSs. We show empirically that bears improves RS-awareness of several state-of-the-art NeSy models, and also facilitates acquiring informative dense annotations for mitigation purposes.},
  eventtitle = {Uncertainty in {{Artificial Intelligenc}}},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning},
}

@inproceedings{NEURIPS2023_4d9944ab,
  title = {A-{{NeSI}}: {{A}} Scalable Approximate Method for Probabilistic Neurosymbolic Inference},
  booktitle = {Advances in Neural Information Processing Systems},
  author = {family=Krieken, given=Emile, prefix=van, useprefix=true and Thanapalasingam, Thiviyan and Tomczak, Jakub and family=Harmelen, given=Frank, prefix=van, useprefix=true and Ten Teije, Annette},
  editor = {Oh, A. and Neumann, T. and Globerson, A. and Saenko, K. and Hardt, M. and Levine, S.},
  date = {2023},
  volume = {36},
  pages = {24586--24609},
  publisher = {Curran Associates, Inc.},
  url = {https://proceedings.neurips.cc/paper_files/paper/2023/file/4d9944ab3330fe6af8efb9260aa9f307-Paper-Conference.pdf}
}

